---
layout: post
title: ORB-SLAM2:An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras 【translation】
date: 2023-3-29 
tags: Paper
---

*This is the translation of the [paper](https://arxiv.org/abs/1610.06475)*

# 摘要：

&emsp;&emsp;本文提出了一种能够使用单目相机、双目相机和RGB-D相机的完整SLAM系统，称为ORB-SLAM2。该系统具有地图复用、回环检测和重定位功能。ORB-SLAM2能够实时在标准的中央处理器上运行，并能够在从小型室内手持设备到工业环境中飞行的无人机再到绕城市行驶的汽车等多种环境下工作。该系统基于带有单双目观测的光束平差法（BA）进行后端优化，从而实现精确的轨迹估计。本文所提出的系统包含一个轻量级的定位模式，该模式利用视觉里程计来跟踪未建图区域并匹配地图点以实现零漂移定位。在29个广泛使用的公开数据集下测试的结果表明，本文所提出的SLAM方法能够在多数情况下获得最高的精度。本文开源代码，不仅为了造福SLAM社区，更是为了给其他研究领域的研究人员提供一个可以直接使用的SLAM解决方案。

关键词：定位，建图，RGB-D，同时定位与建图（SLAM），双目

# I 引言
&emsp;&emsp;同时定位与建图技术（SLAM）在过去的二十年间已经成为计算机视觉和机器人领域中的研究热点，并在近年来吸引着高科技公司的关注。SLAM技术能够建立未知环境的地图并通过高度实时的操作来对地图中的传感器进行定位。在众多传感器中，相机不仅便宜，而且能够为实现鲁棒而准确的位置识别提供丰富的环境信息。因此，以相机为主要传感器的视觉SLAM解决方案成为了主要的研究方向。位置识别是SLAM系统实现回环检测（检测传感器回到了已建图位置并修正建图过程中的累积误差）的关键一环，并且对于实现由陷入闭塞环境或剧烈运动或系统重新初始化导致的轨迹丢失后的重定位起到重要作用。

&emsp;&emsp;视觉SLAM能够通过仅使用一个单目相机实现，这种传感器是最便宜最小的。然而，由于深度信息无法通过单一相机获取，导致了地图规模和估计的轨迹都是不确定的。除此以外，由于不能在初始帧进行三角测量，因此系统自启动需要多视图或滤波器技术来产生一个初始地图。最后，单目SLAM存在尺度漂移问题，如果在传感器探索未知区域的过程中发生了纯旋转则可能会失败。通过使用一个双目相机或RGB-D相机能够解决这些问题并实现最可靠的视觉SLAM。

&emsp;&emsp;本文基于单目ORB-SLAM框架提出ORB-SLAM2，该算法有以下贡献：

1. 第一个具有回环检测、重定位和地图复用功能的开源SLAM系统，并能够使用单目、双目和RGB-D相机实现。
2. RGB-D相机测试结果表明使用光束平差法（BA）获得的结果比基于迭代最近点法（ICP）或广度深度误差最小化法的主流方法更准确。
3. 通过使用远近双目点和单目观测，我们的双目相机测试结果比主流的双目SLAM系统更精确。
4. 轻量级的定位模式使得建图失效时系统能有效对地图进行复用。

&emsp;&emsp;图1给出了ORB-SLAM2系统输入双目和RGB-D相机数据时的输出结果。双目相机结果展现了最终的轨迹和对KITTI数据集中的00数据段的稀疏重建结果。KITTI数据集是一个带有多个回环的城市数据集，ORB-SLAM2能够成功检测到这些回环。RGB-D相机结果展示了TUM RGB-D数据集中的fr1-room数据段的关键帧估计位姿，并给出了根据估计关键帧位姿，对传感器深度图反向投影得到的稠密点云。值得注意的是，本文提出的SLAM方法并没有进行任何形式的融合，如KinectFusion或类似的方法，但是仍然能够精确估计关键帧的位姿。本文算法的更多示例在附件视频中展示。

![fig1](https://effun.xyz/images/ORB-SLAM2/fig1.jpg)

<figure>
图1. ORB-SLAM2处理输入的双目和RGB-D相机数据来估计降级轨迹并建立环境地图。系统能够在实时CPU上运行并实现高精度和鲁棒性的回环检测、重定位和地图复用。(a) 双目输入下：得到轨迹和对包含多闭环的城市环境的重建结果。（b）RGB-D输入下：得到关键帧和仅有一个闭环的室内场景的点云。点云图是根据关键帧对传感器深度图反向投影渲染得到
</figure>

&emsp;&emsp;下面，本文将在第II部分给出相关工作，在第III部分描述本文所设计的系统，接着在第IV部分给出估计结果，最后在第V部分给出结论。


# II 相关工作

&emsp;&emsp;本章将讨论关于双目和RGB-D SLAM的相关工作。本章所讨论的内容与第IV章的估计结果仅针对SLAM方法。

## A. 双目SLAM

&emsp;&emsp;Paz等人开发的SLAM系统是早期优秀的双目SLAM方案。该方案基于条件独立分治的扩展卡尔曼滤波SLAM（EKF-SLAM）实现。并且相比于当时的其他方法，这种方案能在更大的环境下运行。最重要的是，它是第一个同时利用近点和远点（即由于双目相机的左右目图像差异小而不能准确估计其深度的点）的双目SLAM方案，并对远点使用逆参数估计。Paz等人基于工程经验提出当空间点的深度小于双目相机基线的40倍时，其才可以被有效三角化。本文将遵循用不同方式处理远近点的策略，具体解释将在III-A部分给出。

&emsp;&emsp;目前，多数的双目SLAM系统都是基于关键帧实现的，并通过局部BA优化获得可扩展性。Strasdat等人在关键帧滑窗内的BA（点-位姿约束）和外部窗口中的位姿图（位姿-位姿约束）进行联合优化。通过限制滑窗的尺寸，这种方法获得了恒定的时间复杂度，但是代价是不能保证全局一致性。Mei等人提出的RSLAM使用了地标和位姿的相对位置表示方法并在活跃区域进行相对BA，这种方法受到恒定时间约束。RSLAM能够实现闭环，这使得它能够在每一个闭环两边扩展活动区域而不影响全局一致性。最近，有Pire等人提出的S-PTAM方法只进行局部BA，它缺少大规模的回环检测。与这些方法相似的是，本文对局部的一系列关键帧进行BA优化以使得复杂度不受地图尺寸的影响并允许ORB-SLAM2能够在大规模环境下运行。然而，本文的目标是建立一个全局一致的地图。与RSLAM相似的是，当发生回环时，本文所设计的系统能够先将地图两端对齐，使追踪线程可以使用之前的地图持续定位，接着进行位姿图优化以减小闭环中的累积漂移。随后进行全局BA。

&emsp;&emsp;Engel等人最近提出的双目大规模直接SLAM（LSD-SLAM）是一种半稠密直接SLAM方法，能够减小高梯度图像区域的光度误差。这种方法希望能够在不依靠图像特征的情况下，当受到动态扰动或处于纹理较少的环境中时能够更加鲁棒。但是由于这是一种直接法，当受到未建模因素例如卷帘快门和非朗伯反射的影响时，其性能会大幅下降。

## B.RGB-D SLAM

&emsp;&emsp;Newcombe等人提出的KinectFusion是最早最著名的RGB-D SLAM系统之一。这种方法将传感器获得的所有深度数据融合成一个体积稠密模型，用于使用ICP法跟踪相机位姿。受限于体积表示和缺少回环检测，该系统只能在小空间范围内运行。Whelan等人提出的Kintinuous通过设置一个滚动循环缓冲区和包含基于位置识别和位姿图优化的回环检测使得系统能够在大规模场景下运行。

&emsp;&emsp;Endres等人提出的RGB-D SLAM方法可能是第一个受到广泛好评的开源SLAM方案。该方法是基于特征点实现的，其前端通过特征匹配和ICP方法计算帧对帧的运动，后端则进行带有回环的位姿优化，回环约束由启发式搜索得到。与之相似的是Kerl等人提出的DVO-SLAM的后端，优化了带有从视觉里程计中计算得到的关键帧对关键帧约束的位姿图，减少了光度和深度的误差。DVO-SLAM同时还可以在之前的所有帧中搜索候选回环，而不需要依赖位置识别。

&emsp;&emsp;最近由Whelan等人提出的ElasticFusion方法建立了基于surfel的环境地图。这是一种忽略位姿而以地图为核心的方法，它采用对地图进行非刚性变形的方式来实现回环检测，而不是采用标准的位姿图优化。该方法具有惊人的细节重建效果和定位精确度，但是由于复杂度会随surfel的数量增加而大幅提升，因此该方法目前只能限制在室内大小的场景下应用。

&emsp;&emsp;如文献[8]中Strasdat等人提出的方法一样，本文所提出的ORB-SLAM2方法基于深度信息合成立体坐标系，进而提取图像特征。通过这种方法，本文所设计的系统能够处理双目相机或RGB-D相机的输入数据。与以上所有方法不同的是，ORB-SLAM2的后端是基于光束平差法的，并且能够得到全局一致的稀疏重建结果。因此我们的方法是轻量级的并且能够在标准CPU上运行。本文的目标是能够使系统长时间运行并得到全局一致的定位结果而不是进行有着最多细节的稠密重建。然而，由高度精确的关键帧位姿和深度图融合，本文方法依然可以实时得到局部区域的准确三维重建结果，或在全局BA结束后处理所有关键帧的深度图从而得到整个场景的准确三维模型。

# III ORB-SLAM2

&emsp;&emsp;ORB-SLAM2的双目相机模式和RGB-D相机模式是由基于特征点的ORB-SLAM发展而来，其主要的组成部分如下：

![fig2](https://effun.xyz/images/ORB-SLAM2/fig2.jpg)

<figure>
图2. ORB-SLAM2由三个主要的并行线程组成：跟踪线程、建图线程和回环检测线程，回环检测能触发第四个线程即全局BA优化。跟踪线程预处理双目或RGB-D相机的输入数据使得系统其余的部分能够不依赖传感器独立运行。ORB-SLAM2还能够基于单目相机的输入数据运行（图中未给出）。(a)系统各线程与组成模块。(b)输入数据预处理。
</figure>

&emsp;&emsp;系统总体架构如图2所示。ORB-SLAM2包含三个主要的并行线程：

1. 跟踪线程（Tracking）：通过与局部地图进行特征匹配和用运动BA最小化重投影误差来定位每一帧中相机的位置。
2. 局部建图线程（Local Mapping）：管理局部地图并基于局部BA对其进行优化。
3. 回环检测线程（loop closing）：检测大回环并通过位姿图优化修正累积漂移误差。在位姿图优化结束后会触发第四个线程，即全局BA，来计算最优的结构和运动策略。

&emsp;&emsp;本文所设计的系统嵌入了一个基于DBoW2库的位置识别模块来实现重定位功能，避免跟踪线程失效（如出现遮挡）。同时，该模块还可以用于在已建图场景中重新初始化系统和回环检测。ORB-SLAM2系统能够生成关联可见的图用以连接任意两个有共视地图点的关键帧以及连接所有关键帧的最小生成树。这些图结构使得系统能够重新检索关键帧局部窗口，其目的是使跟踪线程和局部建图线程在局部运行，保证系统在大规模环境下工作。当出现回环时，这样的图结构还可以用于位姿图优化。

&emsp;&emsp;ORB-SLAM2系统使用ORB特征完成跟踪、建图和位置识别。ORB特征点具有旋转尺度不变性并且对相机的自动增益和自动曝光以及光照变化具有良好的不变性。除此之外，ORB特征点能够保证实时更快地提取和匹配并在基于Bow的位置识别过程中表现出良好的P/R性能。

&emsp;&emsp;在本节的剩余部分将给出双目或深度信息是如何被应用于系统中的以及系统的哪些部分因此受到影。读者可以在文献[1]即单目ORB-SLAM中获得关于系统每个模块的详细描述。

## A. 单目，近双目和远双目关键点

&emsp;&emsp;如图2(b)所示，ORB-SLAM2作为一种基于特征提取的方法，能够对输入数据进行预处理，在重要的关键点位置提取特征点。预处理结束后，输入的图像信息不再被应用，系统内所有的操作都基于提取的特征点展开，这样保证了系统运行不受传感器是双目相机还是RGB-D相机的限制。本文所设计的系统能够处理单目和双目关键点，这些关键点可以进一步划分为近点和远点。

&emsp;&emsp; 双目关键点由$$\mathbf{x}_\mathbf{s}=(u_L, v_L, u_R)$$三维坐标定义, $$(u_L, v_L)$$为左图的像素坐标，$$u_R$$是右图中的水平坐标。对于双目相机，首先对左右目的两幅图像都进行ORB特征提取，并对每一个左图中的ORB特征点在右图中寻找其匹配点。如果双目相机的图像被矫正过，确保基线水平，那么上述过程可以被高效完成。利用左图ORB特征点的像素坐标和右图对应匹配点的水平坐标可以生成双目关键点，并基于块矫正对这些关键点进行亚像素精细化。对于RGB-D相机，可以在RGB图像中提取ORB特征，并基于文献[8]中Strasdata等人提出的方法，利用每一个特征点的像素坐标$$(u_L, v_L)$$，将其深度值 *d* 转化为右图水平坐标。

$$u_R = u_L - \frac{f_xb}{d}\ \tag{1}$$

其中，$$f_x$$ 是水平焦距，*b* 是结构光发射机和红外相机之间的基线长度，本文所使用的Kinect以及Asus Xtion相机基线长度约为8cm。深度传感器的不确定性由虚拟的右图坐标的不确定性表示。这样一来，系统其它的部分能够对从双目和RGB-D相机输入的图像中提取出的特征点作出同样的处理。

&emsp;&emsp;基于文献[5]中给出的建议，本文规定，当关键点的深度值小于双目或RGB-D相机基线长度的40倍时，将此其定义为近点，否则定义为远点。如果深度值能够被准确地估计，那么近关键点可以安全地从一帧中三角化并提供尺度、平移和旋转信息。另一方面，远点能够提供准确的旋转信息，但是尺度和平移信息则较弱。当远点被从多个视角捕捉时，可以对其进行三角化。

&emsp;&emsp;单目关键点由左图中的$$\mathbf{x_m}=(u_L, v_L)$$定义，并与所有无法进行双目匹配或在使用RGB-D相机的情况下有无效深度值的ORB特征点相关联。这些特征点只能从多个视角进行三角化，它们虽然不能提供尺度信息，但是却有利于旋转和平移的估计结果。

## B.系统引导

&emsp;&emsp;使用双目和RGB-D相机的好处之一是能够从仅一帧中获得深度信息，而不像使用单目相机时需要做特定的SFM初始化。系统启动阶段会利用首帧图像生成关键帧，将其位姿设置为原点，并基于所有的双目关键点生成初始地图。

## C.带有单双目约束的光束平差法

&emsp;&emsp;本文提出的系统能够基于BA法在跟踪线程中优化相机位姿（纯运动BA），在局部建图线程中优化局部窗口内的关键帧和地图点（局部BA）以及在回环检测后优化全部的关键帧和地图点（全局BA）。本文基于g2o库中集成的列文伯格-马夸尔特方法求解BA。

&emsp;&emsp;**纯运动BA**优化相机旋转矩阵$$\mathbf{R}\in SO(3)$$和位置$$\mathbf{t}\in\mathbb{R}^3$$，最小化世界坐标系下互相匹配的3-D点云$$\mathbf{X}^i$$与关键点$$\mathbf{x}^i_{(\centerdot)}$$之间的投影误差。其中，关键点可以是单目点$$\mathbf{x}^i_m\in\mathbb{R}^2$$或双目点$$\mathbf{x}^i_s\in\mathbb{R}^3$$，$$i\in\chi$$，$$\chi$$为全部匹配的集合。

$$\{\mathbf{R}, \mathbf{t}\} =\underset{\mathbf{R,t}}{\mathbf{argmin}} \sum_{i\in\chi}\rho(\big\| \mathbf{x}^i_{(\centerdot)} - \pi_{(\centerdot)}(\mathbf{RX}^i+\mathbf{t}) \big\|^2_\Sigma)\tag{2}$$

其中，$$\rho$$是鲁棒Huber代价函数，$$\Sigma$$是与关键点规模相关的协方差矩阵。投影函数$$\pi_{(\centerdot)}$$在使用单目相机时为$$\pi_m$$，使用校正后的双目相机时为$$\pi_s$$，二者定义如下：

$$ \pi_m\Bigg( 
    \left[ 
        \begin{matrix}
        X\\
        Y\\
        Z
        \end{matrix}
    \right] \Bigg) 
    =
    \left[ 
        \begin{matrix}
         f_x\frac{X}{Z}+c_x \\
         f_y\frac{Y}{Z}+c_y   
        \end{matrix}
    \right]
    ,
    \pi_s\Bigg( 
    \left[ 
        \begin{matrix}
        X\\
        Y\\
        Z
        \end{matrix}
    \right] \Bigg) 
    =
    \left[ 
        \begin{matrix}
         f_x\frac{X}{Z}+c_x \\
         f_y\frac{Y}{Z}+c_y \\
         f_x\frac{X-b}{Z}+c_x
        \end{matrix}
    \right] 
    \tag{3}
$$

其中，$$(f_x,f_y)$$ 是焦距，$$(c_x,c_y)$$ 是主点，$$b$$ 是基线，这些参数均由标定获得。


&emsp;&emsp;**局部BA**对一系列共视的关键帧$$\mathcal{K}_L$$和在这些关键帧中观测到的全部点$$\mathcal{P}_L$$进行优化。所有能够观测到$$\mathcal{P}_L$$中的点但是不在$$\mathcal{K}_L$$中的关键帧$$\mathcal{K}_F$$同样有助于构建代价函数，但是在优化中保持不变。将$$\mathcal{X}_k$$定义为$$\mathcal{P}_L$$中的点和关键帧$$k$$中的关键点之间能够相互匹配的点的集合，则优化问题如下：

$$ \begin{aligned}
    \{\mathbf{X}^i,\mathbf{R}_l,\mathbf{t}_l|i\in\mathcal{P}_L,l\in\mathcal{K}_L\}&=\underset{\mathbf{X}^i,\mathbf{R}_l,\mathbf{t}_l}{\mathbf{argmin}}\sum_{{k\in\mathcal{K}_L}\cup\mathcal{K}_F}\sum_{j\in\mathcal{X}_k}\rho(E(k,j)) \\
    E(k,j) &= \Big\| \mathbf{x}^j_{(\centerdot)}-\pi_{(\centerdot)}(\mathbf{R}_k\mathbf{X}^j+\mathbf{t}_k)\Big\|^2_\Sigma
\end{aligned}$$

&emsp;&emsp;全局BA是局部BA的特殊情况，所有地图中的关键帧和点都会被优化，除了原点关键帧始终固定不变以消除测量自由度。

## D.回环检测与全局BA

=======
&emsp;&emsp;**局部BA**对一系列共视的关键帧$$\mathcal{K}_L$$和在这些关键帧中观测到的全部点$$\mathcal{P}_L$$进行优化。所有能够观测到$$\mathcal{P}_L$$中的点但是不在$$\mathcal{K}_L$$中的关键帧$$\mathcal{K}_F$$同样有助于

